{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from latentis import PROJECT_ROOT\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir: Path = PROJECT_ROOT / \"results\" / \"exp3\"\n",
    "exp_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = list(exp_dir.glob(\"*\"))\n",
    "len([exp.name for exp in experiments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "df = defaultdict(list)\n",
    "for exp_path in experiments:\n",
    "    if not exp_path.is_file():\n",
    "        continue\n",
    "    exp_data = torch.load(exp_path, map_location=\"cpu\", weights_only=False)\n",
    "    for ablation in exp_data[\"ablations\"]:\n",
    "        for k, v in ablation.items():\n",
    "            if k == \"keep_units\" or k == \"ablated_shape\":\n",
    "                continue\n",
    "            if k == \"residual_indices\":\n",
    "                df[\"n_units\"].append(v.numel())\n",
    "            df[k].append(v if not isinstance(v, torch.Tensor) else v.numpy())\n",
    "        df[\"model\"].append(exp_data[\"model_name\"])\n",
    "        df[\"dataset\"].append(exp_data[\"dataset_name\"])\n",
    "df = pd.DataFrame(df)\n",
    "df.drop_duplicates(subset=[\"model\", \"dataset\", \"type\", \"ablation\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"selection_method\"] = df[\"type\"].apply(\n",
    "    lambda x: \"_\".join(x.split(\"_\")[2:]) if x.startswith(\"greedy\") else \"manual\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"n_units\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"selection_method\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs(\"resi_dual/residual\", filters={\"config.exp_type\": \"residual_coarse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.apis.public.runs import Run\n",
    "\n",
    "coarse_data = []\n",
    "for run in runs:\n",
    "    run: Run\n",
    "\n",
    "    coarse_data.append(\n",
    "        {\n",
    "            \"model\": run.config[\"model_name\"],\n",
    "            \"dataset\": run.config[\"dataset_name\"],\n",
    "            \"type\": run.config[\"exp_type\"],\n",
    "            \"score\": run.summary.get(\"test/accuracy\", None),\n",
    "            \"selection_method\": \"optimized\",\n",
    "        }\n",
    "    )\n",
    "coarse_data = pd.DataFrame(coarse_data)\n",
    "\n",
    "coarse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from residual.data.data_registry import dataset_names\n",
    "\n",
    "filtered_df = df.copy()\n",
    "filtered_df = filtered_df[filtered_df[\"model\"].isin({\"openclip_l\", \"blip_l_flickr\"})]\n",
    "filtered_df.drop(\"residual_indices\", axis=1, inplace=True)\n",
    "filtered_df = filtered_df[(filtered_df[\"ablation\"] != \"mean\")]\n",
    "types = {\n",
    "    \"greedy_5%_corr_full_out_heads\": \"U\",\n",
    "    \"greedy_5%_corr_task_heads\": \"U|T\",\n",
    "    \"greedy_5%_supervised_heads\": \"S\",\n",
    "    \"random_mean\": \"R\",\n",
    "    \"heads\": \"H\",\n",
    "    \"units\": \"B\",\n",
    "    \"residual_coarse\": \"O\",\n",
    "    # **{f\"greedy_5%_random_{i}_heads\": \"R\" for i in range(10)},\n",
    "}\n",
    "\n",
    "random_rows = filtered_df[filtered_df[\"type\"].str.contains(\"random\")]\n",
    "\n",
    "# Step 1: Filter rows where 'type' contains 'random'\n",
    "filtered_df = filtered_df[filtered_df[\"type\"].isin(types.keys())]\n",
    "\n",
    "# Step 2: Group by 'model' and 'dataset' and calculate mean and std for each group\n",
    "grouped_random = random_rows.groupby([\"model\", \"dataset\"])\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "result_df = filtered_df[~filtered_df[\"type\"].str.contains(\"random\")].copy()\n",
    "\n",
    "# Initialize a list to collect new rows\n",
    "new_rows = []\n",
    "\n",
    "# Loop through each group and calculate the mean and std, then append to the result dataframe\n",
    "for (model, dataset), group in grouped_random:\n",
    "    # Calculate mean and std for the group\n",
    "    group_mean = group.mean(numeric_only=True)\n",
    "    group_std = group.std(numeric_only=True)\n",
    "\n",
    "    # Prepare new rows for mean and std\n",
    "    mean_row = pd.Series(group_mean, name=f\"random_mean_{model}_{dataset}\")\n",
    "    std_row = pd.Series(group_std, name=f\"random_std_{model}_{dataset}\")\n",
    "\n",
    "    # Add 'model' and 'dataset' information\n",
    "    mean_row[\"model\"] = model\n",
    "    mean_row[\"dataset\"] = dataset\n",
    "    mean_row[\"ablation\"] = \"zero\"\n",
    "    mean_row[\"type\"] = \"random_mean\"\n",
    "\n",
    "    std_row[\"model\"] = model\n",
    "    std_row[\"dataset\"] = dataset\n",
    "    std_row[\"ablation\"] = \"zero\"\n",
    "    std_row[\"type\"] = \"random_std\"\n",
    "\n",
    "    # Append the mean and std rows to the list of new rows\n",
    "    new_rows.append(mean_row)\n",
    "    new_rows.append(std_row)\n",
    "\n",
    "# Step 3: Convert the list of new rows into a DataFrame and concatenate with the result dataframe\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "result_df = pd.concat([result_df, new_rows_df], ignore_index=True)\n",
    "result_df = result_df[result_df[\"type\"] != \"random_std\"]\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from residual.nn.model_registry import model_names\n",
    "\n",
    "result_df = pd.concat(\n",
    "    [result_df, coarse_data[coarse_data[\"model\"].isin(result_df[\"model\"].unique())]],\n",
    "    ignore_index=True,\n",
    ")\n",
    "result_df.sort_values(by=[\"model\", \"dataset\", \"type\"], inplace=True)\n",
    "result_df[\"model\"] = result_df[\"model\"].apply(lambda x: model_names[x])\n",
    "result_df[\"dataset\"] = result_df[\"dataset\"].apply(lambda x: dataset_names[x])\n",
    "\n",
    "result_df[\"type\"] = result_df[\"type\"].apply(types.__getitem__)\n",
    "result_df[\"type\"] = pd.Categorical(result_df[\"type\"], categories=types.values())\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = result_df.pivot(\n",
    "    index=[\"dataset\"], columns=[\"model\", \"type\"], values=\"score\"\n",
    ").fillna(0)\n",
    "# reorder columns\n",
    "table = table[\n",
    "    sorted(table.columns, key=lambda x: (x[0], list(types.values()).index(x[1])))\n",
    "]\n",
    "table = table.to_latex(\n",
    "    multirow=True, column_format=\"c\", multicolumn_format=\"c\", float_format=\"%.2f\"\n",
    ")\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
